#!/usr/bin/env vpython3
# Copyright 2019 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
"""Script to generate Java coverage metadata file.

This script coverts raw coverage data to jacoco_xml format
(defined at https://github.com/SonarSource/sonar-jacoco/blob/master/its/src/test/resources/simple-project-jacoco/jacoco.xml)
and later to code coverage data format (defined at:
https://chromium.googlesource.com/infra/infra/+/refs/heads/main/appengine/findit/model/proto/code_coverage.proto)

Coverage recipe module then uploads both jacoco_xml format and code coverage
data format to GCS, where they get consumed by zoss and coverage service
respectively.
"""

import argparse
from collections import defaultdict
import fnmatch
import json
import logging
import os
import re
import shutil
import subprocess
import sys
import tempfile
from xml.etree import ElementTree
import zlib

import aggregation_util
import blame_util
import combine_jacoco_reports
import repository_util

# The sources_json_file is generated by jacoco_instr.py with source directories
# and input path to non-instrumented jars.
# e.g.
# 'source_dirs': [
#     "chrome/android/java/src/org/chromium/chrome/browser/toolbar/bottom",
#     "chrome/android/java/src/org/chromium/chrome/browser/ui/system",
# ]
# 'input_path':
#   '$CHROMIUM_OUTPUT_DIR/\
#    obj/chrome/android/features/tab_ui/java__process_prebuilt-filtered.jar'
#
# 'output_dir': $CHROMIUM_OUTPUT_DIR

SOURCES_JSON_FILES_SUFFIX = '__jacoco_sources.json'

# These should match the jar class files generated in internal_rules.gni
DEVICE_CLASS_EXCLUDE_SUFFIX = 'host_filter.jar'
HOST_CLASS_EXCLUDE_SUFFIX = 'device_filter.jar'


def get_files_with_suffix(root_dir, suffix):
  """Gets all files with a given suffix.

  Args:
    root_dir: Directory in which to search for files.
    suffix: Suffix to look for.

  Returns:
    A list of absolute paths to files that match.
  """
  files = []
  for root, _, filenames in os.walk(root_dir):
    basenames = fnmatch.filter(filenames, '*' + suffix)
    files.extend([os.path.join(root, basename) for basename in basenames])

  return files


def get_coverage_metric_summaries(tree_root):
  """Gets coverage summaries data to given dictionary.

  Code coverage Metric message definition:
  https://bit.ly/2SeYACG

  Args:
    tree_root: The root element to search for "counter" tag.

  Returns:
    A list of calculated coverage metric summaries.
  """
  summaries = []
  counter_map = {
      counter.attrib['type'].lower(): counter
      for counter in tree_root.findall('counter')
  }

  for metric in combine_jacoco_reports.JAVA_COVERAGE_METRICS:
    summary = {'name': metric, 'covered': 0, 'total': 0}
    if metric in counter_map:
      covered = int(counter_map[metric].attrib['covered'])
      missed = int(counter_map[metric].attrib['missed'])
      summary['covered'] = covered
      summary['total'] = covered + missed
    summaries.append(summary)

  return summaries


def _create_classfile_args(class_files, exclude_suffix=None):
  """Returns a list of files that don't have a given suffix.

  Args:
    class_files: A list of class files.
    exclude_suffix: Suffix to look for to exclude.

  Returns:
    A list of files that don't use the suffix.
  """
  result_class_files = []
  for f in class_files:
    if exclude_suffix:
      if not f.endswith(exclude_suffix):
        result_class_files += ['--classfiles', f]
    else:
      result_class_files += ['--classfiles', f]

  return result_class_files


def _get_file_coverage_data(file_path, source_file, diff_mapping):
  """Gets single source file coverage data from sourcefile element.

  Args:
    file_path: The file path relevant to the src root.
    source_file: The sourcefile element to calculate coverage data.
    diff_mapping: A json object that stores the diff mapping. Only meaningful to
      per-cl coverage.

  Returns:
    A dictionary of calculated source file coverage data.
  """
  file_coverage = {}
  # Source path needs to start with '//', https://bit.ly/2XC80ZL
  file_coverage['path'] = '//' + file_path
  file_coverage['lines'] = []
  file_coverage['branches'] = []

  for line in source_file.findall('line'):
    line_number = line.attrib['nr']
    if diff_mapping and file_path in diff_mapping:
      line_mapping = diff_mapping[file_path]
      if line_number in line_mapping:
        line_number = line_mapping[line_number][0]
      else:
        # Skip this line since it is deleted on Gerrit.
        continue
    line_number = int(line_number)

    covered_instructions = int(line.attrib['ci'])
    missed_branches = int(line.attrib['mb'])
    covered_branches = int(line.attrib['cb'])

    line_coverage = {
        'first': line_number,
        'last': line_number,
        'count': covered_instructions,
    }
    file_coverage['lines'].append(line_coverage)

    if missed_branches > 0 or covered_branches > 0:
      branch_coverage = {
          'line': line_number,
          'covered': covered_branches,
          'total': covered_branches + missed_branches,
      }
      file_coverage['branches'].append(branch_coverage)

  # Add coverage metrics per source file.
  file_coverage['summaries'] = get_coverage_metric_summaries(source_file)
  return file_coverage


def _get_files_coverage_data(src_path,
                             root,
                             diff_mapping,
                             source_files,
                             exclusion_pattern=None,
                             third_party_inclusion_subdirs=None):
  """Gets the files coverage data based on Jacoco XML report.

  Args:
    src_path: Absolute path to the code checkout.
    root: The root element for the JaCoCo XML report ElementTree.
    diff_mapping: A json object that stores the diff mapping. Only meaningful to
      per-cl coverage.
    source_files: List of source files to generate coverage data for,
      paths relative to code checkout. Only meaningful to per-cl coverage.
    exclusion_pattern: A regex string to exclude matches from aggregation.
    third_party_inclusion_subdirs (list): List of third_party subdirs to be
              included in the aggregation

  Returns:
    A list of files coverage data.
  """
  files_set = None
  if source_files:
    files_set = set(source_files)

  files_coverage_data = []
  for package in root.findall('package'):
    package_path = package.attrib['name']
    for source_file in package.findall('sourcefile'):
      source_file_name = source_file.attrib['name']
      file_path = os.path.join(package_path, source_file_name)
      # Only process affected files for per-cl coverage.
      if diff_mapping and file_path not in files_set:
        continue

      if exclusion_pattern and re.match(exclusion_pattern, file_path):
        continue

      # exclude third_party/ code
      if ('third_party/' in file_path and third_party_inclusion_subdirs and
          not any([x in file_path for x in third_party_inclusion_subdirs])):
        continue

      logging.info('Processing file %s', '//' + file_path)
      file_coverage = _get_file_coverage_data(file_path, source_file,
                                              diff_mapping)
      if not file_coverage['lines']:
        logging.info('Skip file %s as no line instrumented', file_path)
        continue
      files_coverage_data.append(file_coverage)

  # Add git revision and timestamp per source file.
  if files_coverage_data and not diff_mapping:
    repository_util.AddGitRevisionsToCoverageFilesMetadata(
        files_coverage_data, src_path, 'DEPS')

  return files_coverage_data


def generate_json_coverage_metadata(src_path,
                                    root,
                                    component_mapping,
                                    diff_mapping,
                                    source_files,
                                    exclusion_pattern=None,
                                    third_party_inclusion_subdirs=None,
                                    generate_blame_list=False):
  """Generates a JSON representation based on Jacoco XML report.

  JSON format conforms to the proto:
  //infra/appengine/findit/model/proto/code_coverage.proto

  Args:
    src_path: Absolute path to the code checkout.
    root: The root element for the JaCoCo XML report ElementTree.
    component_mapping: A JSON object that stores the mapping from dirs to
      monorail components. Only meaningful to full-repo coverage.
    diff_mapping: A json object that stores the diff mapping. Only meaningful to
      per-cl coverage.
    source_files: List of source files to generate coverage data for,
      paths relative to code checkout. Only meaningful to per-cl coverage.
    exclusion_pattern: A regex string to exclude matches from aggregation.
    third_party_inclusion_subdirs (list): List of third_party subdirs to be
                included in the aggregation

  Returns:
    JSON format coverage metadata.
  """
  data = {}
  data['files'] = _get_files_coverage_data(src_path, root, diff_mapping,
                                           source_files, exclusion_pattern,
                                           third_party_inclusion_subdirs)
  filenames = [x['path'][2:] for x in data['files']]
  blame_list = {}
  if generate_blame_list:
    blame_list = blame_util.generate_blame_list(src_path, filenames)

  # Add per directory and component coverage data.
  if data['files'] and component_mapping:
    logging.info('Adding directories and components coverage data ...')

    per_directory_coverage_data, per_component_coverage_data = (
        aggregation_util.get_aggregated_coverage_data_from_files(
            data['files'], component_mapping))

    data['components'] = None
    data['dirs'] = None
    if per_component_coverage_data:
      data['components'] = list(per_component_coverage_data.values())
    if per_directory_coverage_data:
      data['dirs'] = list(per_directory_coverage_data.values())
      data['summaries'] = per_directory_coverage_data['//']['summaries']

  return data, blame_list


def _parse_args(args):
  """Parses the arguments.

  Args:
    args: The passed arguments.

  Returns:
    The parsed arguments as parameters.
  """
  parser = argparse.ArgumentParser(
      description='Generate the Java coverage metadata')
  parser.add_argument(
      '--src-path',
      required=True,
      type=str,
      help='absolute path to the code checkout')
  parser.add_argument(
      '--output-dir',
      required=True,
      type=str,
      help='absolute path to the directory to write the metadata, must exist')
  parser.add_argument(
      '--coverage-dir',
      required=True,
      type=str,
      help='absolute path to the directory to traverse JaCoCo .exec files')
  parser.add_argument(
      '--sources-json-dir',
      required=True,
      type=str,
      help='absolute path to the directory to traverse'
      '*__jacoco_sources.json files')
  parser.add_argument(
      '--dir-metadata-path',
      type=str,
      help='absolute path to json file mapping dirs to metadata')
  parser.add_argument(
      '--source-files',
      nargs='*',
      type=str,
      help='a list of source files to generate coverage data for.'
      'path should be relative to the root of the code checkout.')
  parser.add_argument(
      '--diff-mapping-path',
      type=str,
      help='absolute path to the file that stores the diff mapping')
  parser.add_argument(
      '--exec-filename-pattern',
      required=True,
      type=str,
      help='Regex pattern for .exec filenames to be considered '
      'for generating metadata.')
  parser.add_argument(
      '--exclusion-pattern',
      type=str,
      help='regex pattern for sources to exclude from aggregation')
  parser.add_argument(
      '--third-party-inclusion-subdirs',
      nargs='*',
      type=str,
      help='third_party sub directories to include in aggregation')
  parser.add_argument(
      '--generate-blame-list',
      action='store_true',
      help='generate blame list data for files whose coverage is known')
  params = parser.parse_args(args=args)

  if params.dir_metadata_path and not os.path.isfile(params.dir_metadata_path):
    parser.error('Dir metadata %s is missing' % params.dir_metadata_path)

  if params.diff_mapping_path and not os.path.isfile(params.diff_mapping_path):
    parser.error('Diff mapping %s is missing' % params.diff_mapping_path)

  return params


def _read_and_prune_xml(xml_file):
  """Reads xml_file and returns root for sanitized xml tree.

  Reads data in xml_file and deletes elements from the xml tree which are not
  needed by downstream logic e.g. class and counter tags under package tag."""
  # Command tends to exit with status 0 when it actually failed.
  if not os.path.isfile(xml_file):
    raise Exception("File %s doesn't exist" % xml_file)
  root = ElementTree.parse(xml_file).getroot()
  for package in root.findall('package'):
    for claxx in package.findall('class'):
      package.remove(claxx)
    for counter in package.findall('counter'):
      package.remove(counter)
  return root


def fix_package_paths(xml_root, src_path, source_dirs):
  """Replaces package names in xml with source relative path.

  By default jacoco xml looks something like below

  <report name="JaCoCo Coverage Report">
    <package name="org/chromium/test/broker">
      <sourcefile name="OnDeviceInstrumentationBroker.java">
        <line cb="0" ci="0" mb="0" mi="3" nr="17"/>
        <line cb="0" ci="0" mb="0" mi="3" nr="34"/>
        <line cb="0" ci="0" mb="0" mi="4" nr="35"/>
      </sourcefile>
    </package>
  </report>

  In above <package> names are just java package names in which a <sourcefile>
  is present (only difference being dot is replaced by slash), as jacoco assumes
  that package name would be similar to directory structure. This is not true
  for Chrome world e.g. base/android/... and build/android/... have similar java
  packages. This function returns a new xml tree where <package> names
  represent (source relative) directory path in which a <sourcefile> of interest
  is present.
  """
  new_package_inner_xml = defaultdict(lambda: [])
  for package in xml_root.findall('package'):
    package_path = package.attrib['name']
    logging.info('Processing package %s', package_path)

    # Find package directory according to src root.
    package_source_dirs = []
    for source_dir in source_dirs:
      # Filter out 'out/...' source directories.
      if source_dir.startswith('out/'):
        continue
      # Find all matched source_dirs with package_path.
      if source_dir.endswith(package_path):
        package_source_dirs.append(source_dir)
    # TODO(crbug/966918): Skip auto-generated Java files/packages for now.
    if not package_source_dirs:
      logging.info('Cannot find package %s directory according to src root',
                   package_path)
      continue

    # Find the directory in which a source file exists
    for source_file in package.findall('sourcefile'):
      source_file_name = source_file.attrib['name']
      source_dir_found = False
      # Find the correct source_dir by the source_file_name.
      for candidate in package_source_dirs:
        if os.path.isfile(os.path.join(src_path, candidate, source_file_name)):
          source_dir_found = True
          new_package_inner_xml[candidate].append(source_file)
          break
      if not source_dir_found:
        logging.warning('Cannot find source file %s in code checkout',
                        source_file_name)

  # Create new 'fixed' xml tree
  new_root = ElementTree.Element(xml_root.tag, attrib=xml_root.attrib)
  for package_name, source_files in new_package_inner_xml.items():
    new_package = ElementTree.Element('package', attrib={'name': package_name})
    new_package.extend(source_files)
    new_root.append(new_package)

  return new_root


def main():
  params = _parse_args(sys.argv[1:])

  component_mapping = None
  if params.dir_metadata_path:
    with open(params.dir_metadata_path) as f:
      component_mapping = {
          d: md['monorail']['component']
          for d, md in json.load(f)['dirs'].items()
          if 'monorail' in md and 'component' in md['monorail']
      }

  diff_mapping = None
  if params.diff_mapping_path:
    with open(params.diff_mapping_path) as f:
      diff_mapping = json.load(f)

  assert (component_mapping is None) != (diff_mapping is None), (
      'Either component_mapping (for full-repo coverage) or diff_mapping '
      '(for per-cl coverage) must be specified.')

  coverage_files = get_files_with_suffix(params.coverage_dir, '.exec')
  if not coverage_files:
    raise Exception('No coverage file found under %s' % params.coverage_dir)
  logging.info('Found coverage files: %s', str(coverage_files))

  class_files = []
  source_dirs = []
  sources_json_files = get_files_with_suffix(params.sources_json_dir,
                                             SOURCES_JSON_FILES_SUFFIX)
  for f in sources_json_files:
    with open(f) as json_file:
      json_file_data = json.load(json_file)
      input_paths = json_file_data['input_path']
      output_dir = json_file_data['output_dir']
      # The orchestrator downloads affected src-side files into a cleanup/ dir
      # instead of the usual cache/builder/src chromium checkout dir. This
      # extracts the relpath out of the input_path and joins it with
      # params.src_path.
      corrected_input_paths = []
      for input_path in input_paths:
        rel_input_path = os.path.relpath(input_path, output_dir)
        corrected_input_paths.append(
            os.path.join(params.src_path, rel_input_path))
      class_files.extend(corrected_input_paths)
      source_dirs.extend(json_file_data['source_dirs'])

  if not class_files:
    logging.info('Skip processing data as no source file was affected in CL')
    return

  try:
    cmd = [
        'java', '-jar',
        os.path.join(params.src_path, 'third_party', 'jacoco', 'lib',
                     'jacococli.jar'), 'report'
    ]
    host_coverage_files = [
        f for f in coverage_files if f.endswith('junit_tests.exec') and
        re.match(params.exec_filename_pattern, f)
    ]
    device_coverage_files = [
        f for f in coverage_files if not f.endswith('junit_tests.exec') and
        re.match(params.exec_filename_pattern, f)
    ]

    device_cmd = (
        cmd + device_coverage_files +
        _create_classfile_args(class_files, DEVICE_CLASS_EXCLUDE_SUFFIX))
    host_cmd = cmd + host_coverage_files + _create_classfile_args(
        class_files, HOST_CLASS_EXCLUDE_SUFFIX)

    # JaCoCo XML report will be generated temporarily
    # then parsed to json metadata to --output-file.
    temp_dir = tempfile.mkdtemp()
    temp_device_xml = os.path.join(temp_dir, 'temp_device.xml')
    temp_host_xml = os.path.join(temp_dir, 'temp_host.xml')
    device_cmd += ['--xml', temp_device_xml]
    host_cmd += ['--xml', temp_host_xml]

    cmd_output = subprocess.check_output(device_cmd, text=True)
    logging.info('JaCoCo device XML report generated: %r', cmd_output)
    cmd_output = subprocess.check_output(host_cmd, text=True)
    logging.info('JaCoCo host XML report generated: %r', cmd_output)

    temp_overall_xml = os.path.join(temp_dir, 'temp_overall.xml')
    combine_jacoco_reports.combine_xml_files(temp_overall_xml, temp_device_xml,
                                             temp_host_xml)
    xml_root = fix_package_paths(
        _read_and_prune_xml(temp_overall_xml), params.src_path, source_dirs)

    data, blame_list = generate_json_coverage_metadata(
        params.src_path, xml_root, component_mapping, diff_mapping,
        params.source_files, params.exclusion_pattern,
        params.third_party_inclusion_subdirs, params.generate_blame_list)
    logging.info('Writing fulfilled Java coverage metadata to %s',
                 params.output_dir)
    with open(os.path.join(params.output_dir, 'all.json.gz'), 'wb') as f:
      f.write(zlib.compress(json.dumps(data).encode('utf-8')))

    if params.generate_blame_list:
      blame_list_file = os.path.join(params.output_dir, 'blame.json')
      with open(blame_list_file, 'w') as fp:
        json.dump(blame_list, fp)

    # Write xml tree to disk so that it can be exported to zoss
    ElementTree.ElementTree(xml_root).write(
        os.path.join(params.output_dir, 'coverage.xml'))

  finally:
    shutil.rmtree(temp_dir)



if __name__ == '__main__':
  logging.basicConfig(
      format='[%(asctime)s %(levelname)s] %(message)s', level=logging.INFO)
  sys.exit(main())
